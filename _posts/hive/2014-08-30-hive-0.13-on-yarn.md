---
layout: post
category : hive 
tags : [hive]
---
{% include JB/setup %}

做了一下测试，把hive 0.9升级到0.13.1.

hive 0.9 一直是跑在 hadoop 1.1.2 这个版本的集群上面。

现在整个集群都准备升级到 hadoop 2.4.1这个版本。

找了很久，没有很好的升级方案，基本的方案是 copy warehouse，然后升级 hive.

也是根据这个思路来做的。

集群A（hive 0.9,hadoop 1.1.2,hdfs://10.1.1.1:9000/） 

集群B（hive 0.13.1,yarn,hdfs://10.2.2.2:9000/） 

1. 停止0.9的metastore.

2. 把 0.9 的warehouse通过 distcp  把数据从 1.1.2集群 copy到 2.4.1 集群(copy hdfs from A to B)。

    /usr/local/webserver/hadoop-2.4.1/bin/hadoop  distcp  -D mapreduce.job.queuename=sls_queue_2  -pb -update hftp://10.1.1.1:50070/user/www/hive /user/www/hive/ 

3. dump 0.9 的metastore

    mysqldump -uhive -pxxxxx hive09 >  hive.0.9.metastore.sql.bak 

4. 因为是两个集群，metastore中的一此位置信息要进行替换，因为hive.0.9.metastore.

    sed -i 's/10.1.1.1/10.2.2.2/g'   hive.0.9.metastore.sql.bak 

5. 导入 metastore 0.9 to hive 0.13.1

    mysql > create database hive13;

    mysql -uhive13 -pxxxx hive13 <  hive.0.9.metastore.sql.bak
    
    mysql >   source upgrade-0.9.0-to-0.10.0.mysql.sql

    mysql >   source upgrade-0.10.0-to-0.11.0.mysql.sql

    mysql >   source upgrade-0.11.0-to-0.12.0.mysql.sql

    mysql >   source upgrade-0.12.0-to-0.13.0.mysql.sql


6.更改conf/hive-site.xml

    javax.jdo.option.ConnectionURL
    javax.jdo.option.ConnectionUserName
    javax.jdo.option.ConnectionPassword



后记：

在 0.13里面增加了一个授权，这个东东还没搞明白是怎么一个授权方式。



